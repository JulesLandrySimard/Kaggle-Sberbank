{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn\n",
    "import statsmodels.api as sm\n",
    "import scipy as sc\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_state(df):\n",
    "    df_state = df[~pd.isnull(df.state) & ~pd.isnull(df.build_year)]\n",
    "    df_state_grouped = df_state.groupby('build_year')\n",
    "    maxs={}\n",
    "    for name,group in df_state_grouped:\n",
    "        grp = group.groupby('state').count()['full_sq']\n",
    "        maxs[name] = np.argmax(grp)\n",
    "    df_state_null = df[pd.isnull(df.state)]\n",
    "    df_state_null.build_year = df_state_null.build_year.map(maxs)\n",
    "    df_state_notnull = df[~pd.isnull(df.state)]\n",
    "    df = pd.concat([df_state_notnull,df_state_null])\n",
    "    #df = df.drop('latlon')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('train.csv')\n",
    "    df.timestamp = pd.to_datetime(df.timestamp)\n",
    "    df.lat = df.lat.round(3)\n",
    "    df.lon = df.lon.round(3)\n",
    "    df_test = pd.read_csv('test.csv',parse_dates=['timestamp'])\n",
    "    df = fill_state(df)\n",
    "    df_test = fill_state(df_test)\n",
    "    return df,df_test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df_train,df_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38132, 292)\n"
     ]
    }
   ],
   "source": [
    "# ylog will be log(1+y), as suggested by https://github.com/dmlc/xgboost/issues/446#issuecomment-135555130\n",
    "ylog_train_all = np.log1p(df_train['price_doc'].values)\n",
    "id_test = df_test['id']\n",
    "\n",
    "df_train.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
    "df_test.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Build df_all = (df_train+df_test).join(df_macro)\n",
    "num_train = len(df_train)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "#df_all = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')\n",
    "print(df_all.shape)\n",
    "\n",
    "# Add month-year\n",
    "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "df_all['month'] = df_all.timestamp.dt.month\n",
    "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
    "\n",
    "# Other feature engineering\n",
    "df_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\n",
    "df_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n",
    "\n",
    "# Remove timestamp column (may overfit the model in train)\n",
    "df_all.drop(['timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with categorical values\n",
    "df_numeric = df_all.select_dtypes(exclude=['object'])\n",
    "df_obj = df_all.select_dtypes(include=['object']).copy()\n",
    "\n",
    "for c in df_obj: \n",
    "    df_obj[c] = pd.factorize(df_obj[c])[0]\n",
    "\n",
    "df_values = pd.concat([df_numeric, df_obj], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38132, 297)\n",
      "('X_train_all shape is', (30470, 297))\n",
      "('X_train shape is', (24376, 297))\n",
      "('y_train shape is', (24376,))\n",
      "('X_val shape is', (6094, 297))\n",
      "('y_val shape is', (6094,))\n",
      "('X_test shape is', (7662, 297))\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy values\n",
    "X_all = df_values.values\n",
    "print(X_all.shape)\n",
    "\n",
    "# Create a validation set, with last 20% of data\n",
    "num_val = int(num_train * 0.2)\n",
    "\n",
    "X_train_all = X_all[:num_train]\n",
    "X_train = X_all[:num_train-num_val]\n",
    "X_val = X_all[num_train-num_val:num_train]\n",
    "ylog_train = ylog_train_all[:-num_val]\n",
    "ylog_val = ylog_train_all[-num_val:]\n",
    "\n",
    "X_test = X_all[num_train:]\n",
    "\n",
    "df_columns = df_values.columns\n",
    "\n",
    "print('X_train_all shape is', X_train_all.shape)\n",
    "print('X_train shape is', X_train.shape)\n",
    "print('y_train shape is', ylog_train.shape)\n",
    "print('X_val shape is', X_val.shape)\n",
    "print('y_val shape is', ylog_val.shape)\n",
    "print('X_test shape is', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_all[np.isnan(X_train_all)]=-99999\n",
    "ylog_train_all[np.isnan(ylog_train_all)]=-99999\n",
    "X_train[np.isnan(X_train)]=-99999\n",
    "ylog_train[np.isnan(ylog_train)]=-99999\n",
    "X_val[np.isnan(X_val)]=-99999\n",
    "ylog_val[np.isnan(ylog_val)]=-99999\n",
    "X_test[np.isnan(X_test)]=-99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain_all = xgb.DMatrix(X_train_all, ylog_train_all,missing=-99999)\n",
    "dtrain = xgb.DMatrix(X_train, ylog_train,missing=-99999)\n",
    "dval = xgb.DMatrix(X_val, ylog_val,missing=-99999)\n",
    "dtest = xgb.DMatrix(X_test,missing=-99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-rmse:14.3322\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[20]\tval-rmse:5.16246\n",
      "[40]\tval-rmse:1.89725\n",
      "[60]\tval-rmse:0.765618\n",
      "[80]\tval-rmse:0.428083\n",
      "[100]\tval-rmse:0.355647\n",
      "[120]\tval-rmse:0.341687\n",
      "[140]\tval-rmse:0.338564\n",
      "[160]\tval-rmse:0.337223\n",
      "[180]\tval-rmse:0.336488\n",
      "[200]\tval-rmse:0.335958\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "# Uncomment to tune XGB `num_boost_rounds`\n",
    "partial_model = xgb.train(xgb_params, dtrain, num_boost_round=1000, evals=[(dval, 'val')],\n",
    "                       early_stopping_rounds=50, verbose_eval=20)\n",
    "\n",
    "num_boost_round = partial_model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.train(dict(xgb_params, silent=0), dtrain_all, num_boost_round=num_boost_round)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
