{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dummies(df, list_fields):\n",
    "    df_new = df\n",
    "    for field in list_fields:\n",
    "        df_field = pd.get_dummies(df[field],prefix=field)\n",
    "        df_new = pd.concat([df_new, df_field], axis=1)\n",
    "        df_new.drop(field,axis=1,inplace=True)\n",
    "    return df_new\n",
    "\n",
    "def convert_timestamp(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['timestamp'] = (df['timestamp']-df['timestamp'].min()).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "df_new = create_dummies(train,['product_type','ecology'])\n",
    "df_new.drop('sub_area',axis=1,inplace=True)\n",
    "df_new = convert_timestamp(df_new)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "df_new_test = create_dummies(test,['product_type','ecology'])\n",
    "df_new_test.drop('sub_area',axis=1,inplace=True)\n",
    "df_new_test = convert_timestamp(df_new_test)\n",
    "\n",
    "columns_to_keep = np.intersect1d(df_new.columns,df_new_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new[np.append(columns_to_keep,'price_doc')]\n",
    "df_new_test = df_new_test[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rough cleaning\n",
    "cleaned = df_new.fillna(df_new.mean())[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_cleaned = cleaned.drop('price_doc',axis=1)\n",
    "y_cleaned = cleaned['price_doc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import ShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # Compute the RMSLE \n",
    "    score = np.sqrt(np.mean((np.log(y_true+1)-np.log(y_predict+1))**2))\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    regressor = RandomForestRegressor(n_estimators=20)\n",
    "\n",
    "    # Create grid parameters dictionary\n",
    "    #params = {'n_estimators': [5, 10, 50, 100], 'max_depth': range(1,11), 'min_samples_split': [2, 3, 5]}\n",
    "    params = {'max_depth': range(11,15)}\n",
    "    \n",
    "    # Transform 'performance_metric' into a scoring function\n",
    "    scoring_fnc = make_scorer(performance_metric, greater_is_better=False)\n",
    "\n",
    "    # Create the grid search object\n",
    "    grid = GridSearchCV(estimator=regressor,param_grid=params,scoring=scoring_fnc,cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 13 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "# Fit the training data to the model using grid search\n",
    "reg = fit_model(X_train, y_train)\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print \"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_final = df_new_test.fillna(df_new_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = reg.predict(X_test_final)\n",
    "test['price_doc'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30474</th>\n",
       "      <td>5.417854e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30475</th>\n",
       "      <td>8.222329e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30476</th>\n",
       "      <td>5.991031e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30477</th>\n",
       "      <td>6.713476e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30478</th>\n",
       "      <td>5.044535e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price_doc\n",
       "id                 \n",
       "30474  5.417854e+06\n",
       "30475  8.222329e+06\n",
       "30476  5.991031e+06\n",
       "30477  6.713476e+06\n",
       "30478  5.044535e+06"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test[['id','price_doc']]\n",
    "submission.set_index('id',inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5449646.19298077"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.459370433866\n"
     ]
    }
   ],
   "source": [
    "# RMLSE\n",
    "predictions2 = reg.predict(X_test)\n",
    "epsilon = np.sqrt(np.mean((np.log(predictions2+1)-np.log(y_test+1))**2))\n",
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 10 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "reg = fit_model(X_train_pca, y_train)\n",
    "print \"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.470218760232\n"
     ]
    }
   ],
   "source": [
    "# RMLSE\n",
    "X_test_pca = pca.transform(X_test)\n",
    "predictions2 = reg.predict(X_test_pca)\n",
    "epsilon = np.sqrt(np.mean((np.log(predictions2+1)-np.log(y_test+1))**2))\n",
    "print(epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
