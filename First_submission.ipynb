{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dummies(df, list_fields):\n",
    "    df_new = df\n",
    "    for field in list_fields:\n",
    "        df_field = pd.get_dummies(df[field],prefix=field)\n",
    "        df_new = pd.concat([df_new, df_field], axis=1)\n",
    "        df_new.drop(field,axis=1,inplace=True)\n",
    "    return df_new\n",
    "\n",
    "def convert_timestamp(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['timestamp'] = (df['timestamp']-df['timestamp'].min()).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "df_new = create_dummies(train,['sub_area','product_type','ecology'])\n",
    "df_new = convert_timestamp(df_new)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "df_new_test = create_dummies(test,['sub_area','product_type','ecology'])\n",
    "df_new_test = convert_timestamp(df_new_test)\n",
    "\n",
    "columns_to_keep = np.intersect1d(df_new.columns,df_new_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new[np.append(columns_to_keep,'price_doc')]\n",
    "df_new_test = df_new_test[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rough cleaning\n",
    "cleaned = df_new.fillna(df_new.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = cleaned.drop('price_doc',axis=1)\n",
    "y_train = cleaned['price_doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import ShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true,y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    # sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n",
    "    # sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # TODO: Create a decision tree regressor object\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth': range(1,11)}\n",
    "\n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    grid = GridSearchCV(estimator=regressor,param_grid=params,scoring=scoring_fnc,cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'max_depth' is 7 for the optimal model.\n"
     ]
    }
   ],
   "source": [
    "# Fit the training data to the model using grid search\n",
    "reg = fit_model(X_train, y_train)\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print \"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = df_new_test.fillna(df_new_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = reg.predict(X_test)\n",
    "test['price_doc'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30474</th>\n",
       "      <td>5.495062e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30475</th>\n",
       "      <td>6.554423e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30476</th>\n",
       "      <td>5.495062e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30477</th>\n",
       "      <td>5.974426e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30478</th>\n",
       "      <td>5.495062e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price_doc\n",
       "id                 \n",
       "30474  5.495062e+06\n",
       "30475  6.554423e+06\n",
       "30476  5.495062e+06\n",
       "30477  5.974426e+06\n",
       "30478  5.495062e+06"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test[['id','price_doc']]\n",
    "submission.set_index('id',inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3927348.1556256572"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'id', u'full_sq', u'life_sq', u'floor', u'max_floor', u'material',\n",
      "       u'build_year', u'num_room', u'kitch_sq', u'state',\n",
      "       ...\n",
      "       u'cafe_count_5000_price_4000', u'cafe_count_5000_price_high',\n",
      "       u'big_church_count_5000', u'church_count_5000', u'mosque_count_5000',\n",
      "       u'leisure_count_5000', u'sport_count_5000', u'market_count_5000',\n",
      "       u'price_doc', u'Unnamed: 292'],\n",
      "      dtype='object', length=289)\n"
     ]
    }
   ],
   "source": [
    "print cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480068737987\n"
     ]
    }
   ],
   "source": [
    "#RMLSE\n",
    "predictions2 = reg.predict(X_train)\n",
    "epsilon = 0\n",
    "n=len(y_train)\n",
    "for i in range(0,n):\n",
    "    epsilon += (np.log(predictions2[i]+1)-np.log(y_train.iloc[i]+1))**2\n",
    "epsilon = epsilon/n\n",
    "epsilon = np.sqrt(epsilon)\n",
    "print(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
